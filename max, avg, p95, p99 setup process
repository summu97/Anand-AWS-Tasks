Objective:
You want to scrape the following PostgreSQL query performance metrics into Prometheus â†’ Grafana:
pg_stat_statements_query_stats_calls
pg_stat_statements_query_stats_max_time
pg_stat_statements_query_stats_mean_time
pg_stat_statements_query_duration_histogram_bucket
pg_stat_statements_query_duration_histogram_count
pg_stat_statements_query_duration_histogram_sum
p95 / p99 percentiles for query duration

Scenario:
PostgreSQL is running on a separate virtual machine (VM), while Prometheus is running as a pod in a Kubernetes cluster.
To collect the required metrics from PostgreSQL, we install an exporter (agent as docker container) on the same VM where PostgreSQL is running.
================================================================================
Steps from Database side:
Enable pg_stat_statements extension in PostgreSQL

Step-01: Login to your DB
docker exec -it <postgres_container_name> psql -U <your_postgres_user> -d <your_db>
EX:
docker exec -it postgres psql -U admin -d monitoringdb

Step-02: Then run
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

Step-03: Check it's working
SELECT * FROM pg_stat_statements LIMIT 5;
--------------------------------------------
NOTE:
Ensure these lines are in postgresql.conf
shared_preload_libraries = 'pg_stat_statements'
track_activity_query_size = 2048


Step-04: Enter the container
docker exec -it postgres bash

Step-05: Find the postgresql.conf file:
find / -name postgresql.conf

Common locations:
/var/lib/postgresql/data/postgresql.conf
/var/lib/postgresql/data/pgdata/postgresql.conf
/usr/share/postgresql/postgresql.conf.sample (not the active one)

Step-06: Edit the file using vi or nano (if available)
vi /var/lib/postgresql/data/postgresql.conf

If its not available then:

Update/add the config lines using sed(insie container):

Step-07: First, check if the config already exists
grep shared_preload_libraries /var/lib/postgresql/data/postgresql.conf
Output:
#shared_preload_libraries = ''  # (change requires restart)

Step-08: Now run this inside the container to uncomment and set it
sed -i "s/^#shared_preload_libraries = ''/shared_preload_libraries = 'pg_stat_statements'/" /var/lib/postgresql/data/postgresql.conf

Step-09: Then check if it was updated correctly: 
grep shared_preload_libraries /var/lib/postgresql/data/postgresql.conf
Output:
shared_preload_libraries = 'pg_stat_statements'

Step-10: Now configure track_activity_query_size
grep track_activity_query_size /var/lib/postgresql/data/postgresql.conf

Step-11: Update it to 2048, run this inside the container:
sed -i "s/^#track_activity_query_size = 1024/track_activity_query_size = 2048/" /var/lib/postgresql/data/postgresql.conf

Step-12: Then confirm it worked
grep track_activity_query_size /var/lib/postgresql/data/postgresql.conf
Output:
track_activity_query_size = 2048
------------------------------
Also make sure these are configured:
pg_stat_statements.track = all
pg_stat_statements.save = on

Step-13: Then check if pg_stat_statements.track is available
grep pg_stat_statements.track /var/lib/postgresql/data/postgresql.conf

Step-14: If the line doesn't exist (or is commented differently), you can also append it explicitly
echo "pg_stat_statements.track = 'all'" >> /var/lib/postgresql/data/postgresql.conf

Step-15: Then check if it was updated correctly: 
grep pg_stat_statements.track /var/lib/postgresql/data/postgresql.conf
Output:
pg_stat_statements.track = 'all'

Step-16: Then check if pg_stat_statements.save is available
grep pg_stat_statements.save /var/lib/postgresql/data/postgresql.conf

Step-17: If the line doesn't exist (or is commented differently), you can also append it explicitly
echo "pg_stat_statements.save = on" >> /var/lib/postgresql/data/postgresql.conf

Step-18: Then check if it was updated correctly: 
grep pg_stat_statements.save /var/lib/postgresql/data/postgresql.conf
Output:
pg_stat_statements.save = on
-------------------------

Step-19: Finally, restart the container to apply the changes
exit

Step-20: Then on your host
docker restart postgres
-------------------------
Step-21: Now pg_stat_statements will fully function with these configs active. You can validate with:
docker exec -it postgres psql -U admin -d monitoringdb -c "SELECT * FROM pg_stat_statements LIMIT 5;"


Possible Output:
 userid | dbid  | toplevel |       queryid        |                                                        query               
                                         | plans | total_plan_time | min_plan_time | max_plan_time | mean_plan_time | stddev_plan_time | calls | total_exec_time | min_exec_time | max_exec_time | mean_exec_time |  stddev_exec_time   | rows | shared_blks_hit | shared_blks_read | shared_blks_dirtied | shared_blks_written | local_blks_hit | local_blks_read | local_blks_dirtied | local_blks_written | temp_blks_read | temp_blks_written | blk_read_time | blk_write_time | wal_records | wal_fpi | wal_bytes      
--------+-------+----------+----------------------+---------------------------------------------------------------------------------------------------------------------+-------+-----------------+---------------+---------------+----------------+------------------+-------+-----------------+---------------+---------------+----------------+---------------------+------+-----------------+------------------+---------------------+---------------------+----------------+-----------------+--------------------+--------------------+----------------+-------------------+---------------+----------------+-------------+---------+-----------     
     10 | 16384 | t        |  -144325866263766785 | SELECT * FROM pg_stat_statements LIMIT $1                                  
                                         |     0 |               0 |             0 |             0 |              0 |          
      0 |     4 |        1.089606 |       0.14673 |      0.551857 |      0.2724015 | 0.16364428093046823 |    9 |              
 0 |                0 |                   0 |                   0 |              0 |               0 |                  0 |                  0 |              0 |                 0 |             0 |              0 |           0 |       0 |         0      
     10 | 16384 | t        | -7949564536453581318 | SELECT query, calls, mean_exec_time, total_exec_time FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT $1 |     0 |               0 |             0 |             0 |              0 |          
      0 |     2 |        1.975582 |      0.225987 |      1.749595 |       0.987791 |            0.761804 |    4 |              
 6 |                0 |                   0 |                   0 |              0 |               0 |                  0 |                  0 |              0 |                 0 |             0 |              0 |           0 |       0 |         0      
     10 | 16384 | t        | -8063160503150200351 | CREATE EXTENSION IF NOT EXISTS pg_stat_statements                          
                                         |     0 |               0 |             0 |             0 |              0 |          
      0 |     1 |        5.371085 |      5.371085 |      5.371085 |       5.371085 |                   0 |    0 |              
22 |                4 |                   1 |                   0 |              0 |               0 |                  0 |                  0 |              0 |                 0 |             0 |              0 |           0 |       0 |         0      
(3 rows)


==================
That output is the column headers from the pg_stat_statements view â€” which means pg_stat_statements is now fully enabled and working

Step-22: To view actual query performance, just run
docker exec -it postgres psql -U admin -d monitoringdb -c "SELECT query, calls, mean_exec_time, total_exec_time FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 10;"

Possible Output:
                   query                   | calls |   mean_exec_time    |   total_exec_time   
-------------------------------------------+-------+---------------------+---------------------
 SELECT * FROM pg_stat_statements LIMIT $1 |     1 | 0.22200799999999998 | 0.22200799999999998
(1 row)
==================
NOW ITS TIME TO SET EXPORTER:

=======================================================
Present scenario:
i have Prometheus running as a pod and postgresql as acontainer  i preferred to setup a new exporter that runs as container along with PostgreSQL.

Step-23: Create a new custom queries file for agent

vim queries.yaml
---
pg_stat_statements_query_stats:
  query: |
    SELECT
      queryid,
      query,
      calls,
      total_exec_time,
      (total_exec_time / NULLIF(calls, 0)) AS mean_time,
      max_exec_time
    FROM pg_stat_statements
    WHERE calls > 0
  metrics:
    - queryid:
        usage: "LABEL"
        description: "Query ID"
    - query:
        usage: "LABEL"
        description: "Query text"
    - calls:
        usage: "COUNTER"
        description: "Number of times executed"
    - total_exec_time:
        usage: "COUNTER"
        description: "Total execution time of query"
    - mean_time:
        usage: "GAUGE"
        description: "Average execution time"
    - max_exec_time:
        usage: "GAUGE"
        description: "Max execution time"


pg_stat_statements_query_duration_histogram:
  query: |
    SELECT
      queryid,
      width_bucket(total_exec_time, 0, 1000, 10) AS le,
      COUNT(*) AS bucket_count,
      SUM(total_exec_time) AS bucket_sum
    FROM pg_stat_statements
    GROUP BY queryid, le
  metrics:
    - queryid:
        usage: "LABEL"
        description: "Query ID"
    - le:
        usage: "LABEL"
        description: "Histogram bucket"
    - bucket_count:
        usage: "COUNTER"
        description: "Number of queries in this bucket"
    - bucket_sum:
        usage: "COUNTER"
        description: "Sum of durations in this bucket"
---

Step-24: Run Postgres Exporter Container in PostgreSQL VM

docker run -itd --name pg-exporter \
  --network=host \
  -e DATA_SOURCE_NAME="postgresql://admin:admin123@localhost:5432/monitoringdb?sslmode=disable" \
  -e PG_EXPORTER_EXTEND_QUERY_PATH=/etc/queries.yaml \
  -v /home/myuser/queries.yaml:/etc/queries.yaml \
  quay.io/prometheuscommunity/postgres-exporter

Step-25: verify logs for any possible issues
docker logs pg-exporter | grep -i error
NOTE:
You can access metrics at:
http://VM-IP:9187/metrics

Step-26: Add Exporter to Prometheus(in your prometheus.yml)
scrape_configs:
  - job_name: 'postgres-exporter'
    static_configs:
      - targets: ['<your-host-ip>:9187']

NOTE: 
Verify if the datasource is 'UP'

Step-27: Verify the Metrics
curl -s http://34.66.117.149:9187/metrics | grep pg_stat_statements_query_stats
curl -s http://34.66.117.149:9187/metrics | grep pg_stat_statements_query_duration_histogram
---------------------------------------------
Useful:
docker rm -f pg-exporter
---------------------------------------------
Once everything is running fine then in Grafana dashboard

Step-28: Adding  Grafana dashboard
Panel Title: Top Queries by Avg/Max Execution Time
topk(10, pg_stat_statements_query_stats_mean_time)

In Visualization, use Table or Bar chart(bar chart is giving more flexibility).
Add Tooltip mode: All series for readability.
=============================================

Step-29: To Calculate p95 / p99 Percentiles in Prometheus
Dashboard Panel: PostgreSQL Query Duration (p99)
Panel Title: PostgreSQL Query Duration - P99
Units: Time â†’ seconds (or milliseconds, depending on your metric unit)

Dashboard Panel: PostgreSQL Query Duration (p99)
histogram_quantile(0.99, sum by (le, queryid) (
  rate(pg_stat_statements_query_duration_histogram_bucket_count[5m])
))

with: pg_stat_statements_query_stats_total_exec_time

Panel Title:
PostgreSQL Query Duration - P99
Units:
Time â†’ seconds (or milliseconds, depending on your metric unit)

ðŸ“Š Optional Table Panel: Top Slow Queries by P95
If you want a table showing top slow queries (by queryid) sorted by p95:
topk(10, histogram_quantile(0.95, sum by (le, queryid) (
  rate(pg_stat_statements_query_duration_histogram_bucket_count[5m])
)))

with: pg_stat_statements_query_stats_total_exec_time

Panel Title:
Top 10 Slow Queries (P95 Latency)




