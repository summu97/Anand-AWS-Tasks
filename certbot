Create or modify the Nginx config: 
sudo vim /etc/nginx/sites-available/n8n.techdomeaks.com

server {
    listen 80;
    listen [::]:80;
    server_name n8n.techdomeaks.com;
    return 301 https://$host$request_uri;
}

server {
    listen 443 ssl;
    listen [::]:443 ssl;
    server_name n8n.techdomeaks.com;

    ssl_certificate /etc/letsencrypt/live/n8n.techdomeaks.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/n8n.techdomeaks.com/privkey.pem;
    include /etc/letsencrypt/options-ssl-nginx.conf;
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;

    location / {
        proxy_pass http://135.13.13.70:5678/;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_redirect http://135.13.13.70:5678/ https://n8n.techdomeaks.com/;
    }
}
----------------------------------------------------------
sudo vim /etc/nginx/sites-available/mail.techdomeaks.com

server {
    listen 80;
    server_name mail.techdomeaks.com;
    return 301 https://$host$request_uri;
}

server {
    listen 443 ssl;
    server_name mail.techdomeaks.com;

    ssl_certificate /etc/letsencrypt/live/mail.techdomeaks.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/mail.techdomeaks.com/privkey.pem;
    include /etc/letsencrypt/options-ssl-nginx.conf;
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;

    location / {
        proxy_pass https://135.13.13.70:2443/billion;
        proxy_ssl_verify off;

        proxy_set_header Host 135.13.13.70:2443;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}


--------------------------------------------------------------------
sudo vim /etc/nginx/sites-available/flowise.techdomeaks.com

server {
    listen 80;
    listen [::]:80;
    server_name flowise.techdomeaks.com;
    return 301 https://$host$request_uri;
}

server {
    listen 443 ssl;
    listen [::]:443 ssl;
    server_name flowise.techdomeaks.com;

    ssl_certificate /etc/letsencrypt/live/flowise.techdomeaks.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/flowise.techdomeaks.com/privkey.pem;
    include /etc/letsencrypt/options-ssl-nginx.conf;
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;

    location / {
        proxy_pass http://135.13.13.70:3000/;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_redirect http://135.13.13.70:3000/ https://flowise.techdomeaks.com/;
    }
}
--------------------------------------------------------------------------------
Enable the Site and Reload Nginx:
sudo ln -s /etc/nginx/sites-available/n8n.techdomeaks.com /etc/nginx/sites-enabled/
sudo ln -s /etc/nginx/sites-available/flowise.techdomeaks.com /etc/nginx/sites-enabled/
sudo ln -s /etc/nginx/sites-available/mail.techdomeaks.com /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx
----------------------------------
I wanted to inform you about an issue I encountered while deploying the Billionmail application on our current VM.

Billionmail requires ports 80 and 443 for its web and secure mail services. However, these ports are already in use by two other applications that are hosted via NGINX, and are configured with certificates and domain names.

Due to this port conflict, Billionmail is failing to start and cannot bind to the required ports.

üõ† Troubleshooting Done:
Verified container configuration and exposed ports

Confirmed NGINX is already using 80/443 for existing services

Considered alternative ports (e.g., 8080/8443) but this may not be optimal for production email access which relies on standard ports

‚úÖ Proposed Solution:
To avoid impacting the existing services, I suggest deploying Billionmail on a separate server or VM where it can use ports 80 and 443 without conflict.

This would ensure:

Clean separation of services

No disruption to existing hosted applications

Compliance with default port expectations for mail services (e.g., SMTP, IMAP, HTTPS)

Please let me know your thoughts or if you'd prefer an alternative approach such as reverse proxying with NGINX, though that could introduce added complexity.
-----------------------
1. Max, Avg Query Time
SELECT
  query,
  calls,
  round(mean_time, 2) AS avg_time_ms,
  round(max_time, 2) AS max_time_ms,
  total_time::numeric(10,2),
  rows
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;

This will show:
Query text
Number of executions
Avg and max execution time
Total time spent
Rows returned



 Top Queries by Total Time Spent
SELECT
  query,
  total_time,
  calls,
  round(total_time / calls, 2) AS avg_time_per_call
FROM pg_stat_statements
ORDER BY total_time DESC
LIMIT 10;

Percentile Estimation (p95, p99)
PostgreSQL‚Äôs pg_stat_statements doesn‚Äôt give percentile metrics by default. However, if your query logs or a custom table records per-query durations, you can do:
SELECT
  percentile_disc(0.95) WITHIN GROUP (ORDER BY duration) AS p95,
  percentile_disc(0.99) WITHIN GROUP (ORDER BY duration) AS p99
FROM query_duration_log;


For this to work, you'd need to log each query's execution time in a table like query_duration_log(query TEXT, duration FLOAT, time TIMESTAMP).


4. Add Time Filter in Grafana
To allow filtering over time (e.g., last 24h), your SQL must reference a timestamp column and add:
WHERE $__timeFilter(timestamp_column)

But pg_stat_statements doesn't store per-query timestamps, so if you need filtering over time ranges, you‚Äôll need to:

Log queries yourself (with triggers or event triggers)

Or use pg_stat_statements_reset() manually to "start fresh" and analyze from that point onward




--------------------------------
- To find queries taking maximum or average time (already supported in Dashboard ID 9628):
| Metric Name                                | What it tells you                      |
| ------------------------------------------ | -------------------------------------- |
| `pg_stat_statements_query_stats_calls`     | How many times each query was executed |
| `pg_stat_statements_query_stats_max_time`  | Maximum execution time for each query  |
| `pg_stat_statements_query_stats_mean_time` | Average execution time for each query  |

Use case:
Identify queries with highest average response time.
Spot queries with spikes in execution time.


- To calculate P95/P99 latency (requires histogram data):
| Metric Name                                          | Purpose                                        |
| ---------------------------------------------------- | ---------------------------------------------- |
| `pg_stat_statements_query_duration_histogram_bucket` | Required for calculating percentiles (p95/p99) |
| `pg_stat_statements_query_duration_histogram_count`  | Count of queries in each histogram bucket      |
| `pg_stat_statements_query_duration_histogram_sum`    | Total duration of all queries in a bucket      |



Use case:
Use Prometheus function histogram_quantile(0.95, ...) or histogram_quantile(0.99, ...) to visualize query latency percentiles over time.

Final Summary:
| Use Case               | Dashboard 9628 | Extra Setup Needed                       |
| ---------------------- | -------------- | ---------------------------------------- |
| Max/Average Query Time | ‚úÖ Yes          | ‚ùå No                                     |
| Query Latency P95/P99  | ‚ùå No           | ‚úÖ Yes (histogram support, custom panels) |
